{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Predicting Upvotes Based on Headline\n",
    "## Introduction\n",
    "Hacker News is a community where users can submit articles, and other users can upvote those articles. The articles with the most upvotes make it to the front page, where they're more visible to the community.\n",
    "## Goal\n",
    "In this project, I'll be predicting the number of upvotes articles received, based on their headlines. Because upvotes are an indicator of popularity, I'll discover which types of articles tend to be the most popular.\n",
    "## Data\n",
    "\n",
    "The data set consists of submissions users made to Hacker News from 2006 to 2015. Developer Arnaud Drizard used the Hacker News API to scrape the data, which can be found in one of his [GitHub repositories](https://github.com/arnauddri/hn).\n",
    "\n",
    "* `submission_time` - When the article was submitted\n",
    "* `upvotes` - The number of upvotes the article received\n",
    "* `url` - The base URL of the article\n",
    "* `headline` - The article's headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"stories.csv\")\n",
    "data.columns = [\"id\", \"submission_time\", \"submission_id\", \"author\", \"upvotes\", \"url\", \"num_comments\", \"headline\"]\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns I don't need\n",
    "data = data.drop([\"id\", \"submission_id\", \"author\", \"num_comments\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455868, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is pretty large, I'm going to shuffle the rows of the data frame and use a quarter of the data for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363967\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "shuffled_index = np.random.permutation(data.index)\n",
    "data = data.reindex(shuffled_index)\n",
    "\n",
    "#number of rows I want\n",
    "print(int(len(data) / 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>78295</td>\n",
       "      <td>2015-01-05T16:20:01.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>Safe Conferences Are Deliberately Designed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865250</td>\n",
       "      <td>2012-03-27T15:23:57Z</td>\n",
       "      <td>1</td>\n",
       "      <td>nikefreerun2shoesuk.com</td>\n",
       "      <td>Nike Free 7.0 V2 Men's Shoes In Black / Gray /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>679984</td>\n",
       "      <td>2012-10-29T22:52:24Z</td>\n",
       "      <td>3</td>\n",
       "      <td>neillcorlett.com</td>\n",
       "      <td>y Own HTTP Daemon - Simple daemon in Linux x86...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 submission_time  upvotes                      url  \\\n",
       "78295   2015-01-05T16:20:01.000Z        1               medium.com   \n",
       "865250      2012-03-27T15:23:57Z        1  nikefreerun2shoesuk.com   \n",
       "679984      2012-10-29T22:52:24Z        3         neillcorlett.com   \n",
       "\n",
       "                                                 headline  \n",
       "78295          Safe Conferences Are Deliberately Designed  \n",
       "865250  Nike Free 7.0 V2 Men's Shoes In Black / Gray /...  \n",
       "679984  y Own HTTP Daemon - Simple daemon in Linux x86...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new df of my desired length\n",
    "submissions = data.iloc[:363967]\n",
    "submissions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "My goal is to train a linear regression algorithm that predicts the number of upvotes a headline would receive. To do this, I'll need to convert each headline to a numerical representation. I will be using the 'bag of words' model, which represents each piece of text as a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Safe', 'Conferences', 'Are', 'Deliberately', 'Designed'], ['Nike', 'Free', '7.0', 'V2', \"Men's\", 'Shoes', 'In', 'Black', '/', 'Gray', '/', 'Orange', '-', '$52.68', ':', 'Nike', 'Free', 'Run'], ['y', 'Own', 'HTTP', 'Daemon', '-', 'Simple', 'daemon', 'in', 'Linux', 'x86', 'assembly'], ['emory', 'card', 'xbox', '360'], ['OWC', 'launching', 'SandForce-based', 'SSDs', 'for', 'latest', 'MacBook', 'Air']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_headlines = []\n",
    "for item in submissions['headline']:\n",
    "    tokenized_headlines.append(item.split())\n",
    "\n",
    "#preview the data  \n",
    "print(tokenized_headlines[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my tokens, I know they will need some processing to help with making predictions later on. I will need to get rid of punctuation, and make all words lowercase for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"â€™\", \"?\", \"/\", \n",
    "               \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_headlines:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        tokens.append(token)\n",
    "    clean_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will retrieve all unique words from each headline, create a matrix, and assign those words as column headers. After, I will populate the matrix with the number of token occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = []\n",
    "single_tokens = []\n",
    "for tokens in clean_tokenized:\n",
    "    for token in tokens:\n",
    "        if token not in single_tokens:\n",
    "            single_tokens.append(token)\n",
    "        elif token in single_tokens and token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n",
    "\n",
    "counts = pd.DataFrame(0, index=np.arange(len(clean_tokenized)), columns=unique_tokens)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
