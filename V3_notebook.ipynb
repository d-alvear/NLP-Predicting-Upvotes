{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Predicting Upvotes Based on Headline\n",
    "## Introduction\n",
    "Hacker News is a community where users can submit articles, and other users can upvote those articles. The articles with the most upvotes make it to the front page, where they're more visible to the community.\n",
    "## Goal\n",
    "In this project, I'll be predicting the number of upvotes articles received, based on their headlines. Because upvotes are an indicator of popularity, I'll discover which types of articles tend to be the most popular.\n",
    "## Data\n",
    "\n",
    "The data set consists of submissions users made to Hacker News from 2006 to 2015. Developer Arnaud Drizard used the Hacker News API to scrape the data, which can be found in one of his [GitHub repositories](https://github.com/arnauddri/hn).\n",
    "\n",
    "* `submission_time` - When the article was submitted\n",
    "* `upvotes` - The number of upvotes the article received\n",
    "* `url` - The base URL of the article\n",
    "* `headline` - The article's headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>author</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9079983</td>\n",
       "      <td>2015-02-20T11:34:22.000Z</td>\n",
       "      <td>1424432062</td>\n",
       "      <td>Rutger24s</td>\n",
       "      <td>1</td>\n",
       "      <td>startupjuncture.com</td>\n",
       "      <td>0</td>\n",
       "      <td>24sessions: live business advice over video-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9079986</td>\n",
       "      <td>2015-02-20T11:35:32.000Z</td>\n",
       "      <td>1424432132</td>\n",
       "      <td>AndrewDucker</td>\n",
       "      <td>3</td>\n",
       "      <td>blog.erratasec.com</td>\n",
       "      <td>0</td>\n",
       "      <td>Some notes on SuperFish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9079988</td>\n",
       "      <td>2015-02-20T11:36:18.000Z</td>\n",
       "      <td>1424432178</td>\n",
       "      <td>davidiach</td>\n",
       "      <td>1</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple Watch models could contain 29.16g of gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9080000</td>\n",
       "      <td>2015-02-20T11:41:06.000Z</td>\n",
       "      <td>1424432466</td>\n",
       "      <td>CiaranR</td>\n",
       "      <td>1</td>\n",
       "      <td>phpconference.co.uk</td>\n",
       "      <td>0</td>\n",
       "      <td>PHP UK Conference Diversity Scholarship Programme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9080006</td>\n",
       "      <td>2015-02-20T11:43:04.000Z</td>\n",
       "      <td>1424432584</td>\n",
       "      <td>mstolpm</td>\n",
       "      <td>2</td>\n",
       "      <td>preview.onedrive.com</td>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft giving away 100GB free OneDrive stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           submission_time  submission_id        author  upvotes  \\\n",
       "0  9079983  2015-02-20T11:34:22.000Z     1424432062     Rutger24s        1   \n",
       "1  9079986  2015-02-20T11:35:32.000Z     1424432132  AndrewDucker        3   \n",
       "2  9079988  2015-02-20T11:36:18.000Z     1424432178     davidiach        1   \n",
       "3  9080000  2015-02-20T11:41:06.000Z     1424432466       CiaranR        1   \n",
       "4  9080006  2015-02-20T11:43:04.000Z     1424432584       mstolpm        2   \n",
       "\n",
       "                    url  num_comments  \\\n",
       "0   startupjuncture.com             0   \n",
       "1    blog.erratasec.com             0   \n",
       "2           twitter.com             0   \n",
       "3   phpconference.co.uk             0   \n",
       "4  preview.onedrive.com             2   \n",
       "\n",
       "                                            headline  \n",
       "0   24sessions: live business advice over video-chat  \n",
       "1                            Some notes on SuperFish  \n",
       "2    Apple Watch models could contain 29.16g of gold  \n",
       "3  PHP UK Conference Diversity Scholarship Programme  \n",
       "4  Microsoft giving away 100GB free OneDrive stor...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "submissions = pd.read_csv(\"stories.csv\")\n",
    "submissions.columns = [\"id\", \"submission_time\", \"submission_id\", \"author\", \"upvotes\", \"url\", \"num_comments\", \"headline\"]\n",
    "submissions = submissions.dropna()\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-02-20T11:34:22.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>startupjuncture.com</td>\n",
       "      <td>24sessions: live business advice over video-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-02-20T11:35:32.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>blog.erratasec.com</td>\n",
       "      <td>Some notes on SuperFish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-02-20T11:36:18.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>Apple Watch models could contain 29.16g of gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-02-20T11:41:06.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>phpconference.co.uk</td>\n",
       "      <td>PHP UK Conference Diversity Scholarship Programme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-02-20T11:43:04.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>preview.onedrive.com</td>\n",
       "      <td>Microsoft giving away 100GB free OneDrive stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            submission_time  upvotes                   url  \\\n",
       "0  2015-02-20T11:34:22.000Z        1   startupjuncture.com   \n",
       "1  2015-02-20T11:35:32.000Z        3    blog.erratasec.com   \n",
       "2  2015-02-20T11:36:18.000Z        1           twitter.com   \n",
       "3  2015-02-20T11:41:06.000Z        1   phpconference.co.uk   \n",
       "4  2015-02-20T11:43:04.000Z        2  preview.onedrive.com   \n",
       "\n",
       "                                            headline  \n",
       "0   24sessions: live business advice over video-chat  \n",
       "1                            Some notes on SuperFish  \n",
       "2    Apple Watch models could contain 29.16g of gold  \n",
       "3  PHP UK Conference Diversity Scholarship Programme  \n",
       "4  Microsoft giving away 100GB free OneDrive stor...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions = submissions.drop([\"id\", \"submission_id\", \"author\", \"num_comments\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455868, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "My goal is to train a linear regression algorithm that predicts the number of upvotes a headline would receive. To do this, I'll need to convert each headline to a numerical representation. I will be using the 'bag of words' model, which represents each piece of text as a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['24sessions:', 'live', 'business', 'advice', 'over', 'video-chat'], ['Some', 'notes', 'on', 'SuperFish'], ['Apple', 'Watch', 'models', 'could', 'contain', '29.16g', 'of', 'gold'], ['PHP', 'UK', 'Conference', 'Diversity', 'Scholarship', 'Programme'], ['Microsoft', 'giving', 'away', '100GB', 'free', 'OneDrive', 'storage', 'for', '1', 'year']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_headlines = []\n",
    "for item in submissions['headline']:\n",
    "    tokenized_headlines.append(item.split())\n",
    "\n",
    "#preview the data  \n",
    "print(tokenized_headlines[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my tokens, I know they will need some processing to help with making predictions later on. I will need to get rid of punctuation, and make all words lowercase for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"’\", \"?\", \"/\", \n",
    "               \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_headlines:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        tokens.append(token)\n",
    "    clean_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will retrieve all unique words from each headline, create a matrix, and assign those words as column headers. After, I will populate the matrix with the number of token occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ccb86c993611>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msingle_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0msingle_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msingle_tokens\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_tokens\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0munique_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "unique_tokens = []\n",
    "single_tokens = []\n",
    "for tokens in clean_tokenized:\n",
    "    for token in tokens:\n",
    "        if token not in single_tokens:\n",
    "            single_tokens.append(token)\n",
    "        elif token in single_tokens and token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n",
    "\n",
    "counts = pd.DataFrame(0, index=np.arange(len(clean_tokenized)), columns=unique_tokens)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
