{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Predicting Upvotes Based on Headline\n",
    "## Introduction\n",
    "Hacker News is a community where users can submit articles, and other users can upvote those articles. The articles with the most upvotes make it to the front page, where they're more visible to the community.\n",
    "## Goal\n",
    "In this project, I'll be predicting the number of upvotes articles received, based on their headlines. Because upvotes are an indicator of popularity, I'll discover which types of articles tend to be the most popular.\n",
    "## Data\n",
    "\n",
    "The data set consists of submissions users made to Hacker News from 2006 to 2015. Developer Arnaud Drizard used the Hacker News API to scrape the data, which can be found in one of his [GitHub repositories](https://github.com/arnauddri/hn). I've sampled 3000 rows from the data randomly, and removed all of the extraneous columns. I will solely be working with the following four columns:\n",
    "\n",
    "* `submission_time` - When the article was submitted\n",
    "* `upvotes` - The number of upvotes the article received\n",
    "* `url` - The base URL of the article\n",
    "* `headline` - The article's headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-17T16:57:59Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blog.jonasbandi.net</td>\n",
       "      <td>Software: Sadly we did adopt from the construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-04T02:36:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>blogs.wsj.com</td>\n",
       "      <td>Google’s Stock Split Means More Control for L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2011-10-26T07:11:29Z</td>\n",
       "      <td>1</td>\n",
       "      <td>threatpost.com</td>\n",
       "      <td>SSL DOS attack tool released exploiting negoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2011-04-03T15:43:44Z</td>\n",
       "      <td>67</td>\n",
       "      <td>algorithm.com.au</td>\n",
       "      <td>Immutability and Blocks Lambdas and Closures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-13T16:49:20Z</td>\n",
       "      <td>1</td>\n",
       "      <td>winmacsofts.com</td>\n",
       "      <td>Comment optimiser la vitesse de Wordpress?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        submission_time  upvotes                  url  \\\n",
       "0  2010-02-17T16:57:59Z        1  blog.jonasbandi.net   \n",
       "1  2014-02-04T02:36:30Z        1        blogs.wsj.com   \n",
       "2  2011-10-26T07:11:29Z        1       threatpost.com   \n",
       "3  2011-04-03T15:43:44Z       67     algorithm.com.au   \n",
       "4  2013-01-13T16:49:20Z        1      winmacsofts.com   \n",
       "\n",
       "                                            headline  \n",
       "0  Software: Sadly we did adopt from the construc...  \n",
       "1   Google’s Stock Split Means More Control for L...  \n",
       "2  SSL DOS attack tool released exploiting negoti...  \n",
       "3       Immutability and Blocks Lambdas and Closures  \n",
       "4         Comment optimiser la vitesse de Wordpress?  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "submissions = pd.read_csv(\"sel_hn_stories.csv\")\n",
    "submissions.columns = [\"submission_time\", \"upvotes\", \"url\", \"headline\"]\n",
    "submissions = submissions.dropna()\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "My goal is to train a linear regression algorithm that predicts the number of upvotes a headline would receive. To do this, I'll need to convert each headline to a numerical representation. I will be using the 'bag of words' model, which represents each piece of text as a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Software:', 'Sadly', 'we', 'did', 'adopt', 'from', 'the', 'construction', 'analogy'], ['Google’s', 'Stock', 'Split', 'Means', 'More', 'Control', 'for', 'Larry', 'and', 'Sergey'], ['SSL', 'DOS', 'attack', 'tool', 'released', 'exploiting', 'negotiation', 'overhead'], ['Immutability', 'and', 'Blocks', 'Lambdas', 'and', 'Closures'], ['Comment', 'optimiser', 'la', 'vitesse', 'de', 'Wordpress?']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_headlines = []\n",
    "for item in submissions['headline']:\n",
    "    tokenized_headlines.append(item.split())\n",
    "\n",
    "#preview the data  \n",
    "print(tokenized_headlines[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my tokens, I know they will need some processing to help with making predictions later on. I will need to get rid of punctuation, and make all words lowercase for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"’\", \"?\", \"/\", \n",
    "               \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_headlines:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        tokens.append(token)\n",
    "    clean_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will retrieve all unique words from each headline, create a matrix, and assign those words as column headers. After, I will populate the matrix with the number of token occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>as</th>\n",
       "      <th>you</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>split</th>\n",
       "      <th>good</th>\n",
       "      <th>how</th>\n",
       "      <th>what</th>\n",
       "      <th>...</th>\n",
       "      <th>frameworks</th>\n",
       "      <th>animated</th>\n",
       "      <th>walks</th>\n",
       "      <th>auctions</th>\n",
       "      <th>clouds</th>\n",
       "      <th>hammer</th>\n",
       "      <th>autonomous</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>crowdsourcing</th>\n",
       "      <th>disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  for  as  you  is  the  split  good  how  what  ...  frameworks  \\\n",
       "0    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "1    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "2    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "3    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "4    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "\n",
       "   animated  walks  auctions  clouds  hammer  autonomous  vehicle  \\\n",
       "0         0      0         0       0       0           0        0   \n",
       "1         0      0         0       0       0           0        0   \n",
       "2         0      0         0       0       0           0        0   \n",
       "3         0      0         0       0       0           0        0   \n",
       "4         0      0         0       0       0           0        0   \n",
       "\n",
       "   crowdsourcing  disaster  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              0         0  \n",
       "3              0         0  \n",
       "4              0         0  \n",
       "\n",
       "[5 rows x 2310 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = []\n",
    "single_tokens = []\n",
    "for tokens in clean_tokenized:\n",
    "    for token in tokens:\n",
    "        if token not in single_tokens:\n",
    "            single_tokens.append(token)\n",
    "        elif token in single_tokens and token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n",
    "\n",
    "counts = pd.DataFrame(0, index=np.arange(len(clean_tokenized)), columns=unique_tokens)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>as</th>\n",
       "      <th>you</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>split</th>\n",
       "      <th>good</th>\n",
       "      <th>how</th>\n",
       "      <th>what</th>\n",
       "      <th>...</th>\n",
       "      <th>frameworks</th>\n",
       "      <th>animated</th>\n",
       "      <th>walks</th>\n",
       "      <th>auctions</th>\n",
       "      <th>clouds</th>\n",
       "      <th>hammer</th>\n",
       "      <th>autonomous</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>crowdsourcing</th>\n",
       "      <th>disaster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  for  as  you  is  the  split  good  how  what  ...  frameworks  \\\n",
       "0    0    0   0    0   0    1      0     0    0     0  ...           0   \n",
       "1    1    1   0    0   0    0      1     0    0     0  ...           0   \n",
       "2    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "3    2    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "4    0    0   0    0   0    0      0     0    0     0  ...           0   \n",
       "\n",
       "   animated  walks  auctions  clouds  hammer  autonomous  vehicle  \\\n",
       "0         0      0         0       0       0           0        0   \n",
       "1         0      0         0       0       0           0        0   \n",
       "2         0      0         0       0       0           0        0   \n",
       "3         0      0         0       0       0           0        0   \n",
       "4         0      0         0       0       0           0        0   \n",
       "\n",
       "   crowdsourcing  disaster  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              0         0  \n",
       "3              0         0  \n",
       "4              0         0  \n",
       "\n",
       "[5 rows x 2310 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, item in enumerate(clean_tokenized):\n",
    "    for token in item:\n",
    "        if token in unique_tokens:\n",
    "            counts.iloc[i][token] += 1\n",
    "            \n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Columns to Increase Accuracy\n",
    "My resulting matrix contains over 2000 columns. This will make it difficult to implement a linear regression model to make accurate predictions. To fix this, I will remove all columns that represent stopwords and words that occur less than 5 times or more than 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 661)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = counts.sum(axis=0)\n",
    "\n",
    "counts = counts.loc[:,(word_counts >= 5) & (word_counts <= 100)]\n",
    "\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651.1457056689683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, submissions[\"upvotes\"], test_size=0.2, random_state=1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(predictions, y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly large error. In this case, the mean number of upvotes is 10, and the standard deviation is 39.5. The square root of the MSE is 51.5. This means the average error is 51.5 upvotes away from the true value. This is higher than the standard deviation, so my predictions are far off-base.\n",
    "\n",
    "To Do:\n",
    "* add headline length, average word length\n",
    "* use random forest or another technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deand\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395.3236084823275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(preds, y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing a random forest, I reduced the error to 48.9 upvotes which is a small improvement but still a large error. I suspect there are some stopwords in my data set that can be removed and incease my model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['as', 'you', 'good', 'what', 'de', 'amazon', 'cloud', 'at',\n",
       "       'google', 'back', 'raises', 'an', '2014', 'out', 'show', 'dont',\n",
       "       'from', 'video', 'facebook', 'via', 'startups', 'testing',\n",
       "       'releases', 'into', 'job', 'released', 'or', 'it', 'icrosoft',\n",
       "       'programming', 'new', 'using', 'email', 'most', 'api', 'network',\n",
       "       'first', 'but', 'hn', 'startup', 'security', 'part', '1', 'get',\n",
       "       'really', 'rich', 'open', 'online', 'years', 'after', 'his',\n",
       "       'live', 'not', 'china', 'web', 'three', 'hour', 'all', '[video]',\n",
       "       '–', 'app', 'power', 'us', 'tv', 'why', 'top', 'windows', 'hacker',\n",
       "       'microsoft', 'that', 'now', 'think', 'companies', 'can', 'control',\n",
       "       'hack', 'may', 'introducing', 'this', 'my', 'twitter', 'tech',\n",
       "       'internet', 'i', 'nsa', 'find', 'by', 'stop', 'them', 'traffic',\n",
       "       'blog', 'some', 'best', 'own', 'success', 'industry', 'search',\n",
       "       'time', 'start', 'its', 'realtime', 'chat', 'images', 'need',\n",
       "       'test', 'are', 'guide', 'files', 'mac', 'tell', 'business',\n",
       "       'technology', 'design', 'be', 'build', 'apps', 'phone', 'so',\n",
       "       'one', 'space', 'make', 'reddit', 'data', 'software', 'any',\n",
       "       'camera', 'being', 'iphone', '4', 'bill', 'under', '5', 'create',\n",
       "       'access', 'mobile', 'browser', 'school', 'goes', 'government',\n",
       "       'service', 'great', 'block', 'problem', 'culture', 'release',\n",
       "       'computer', 'platform', 'building', 'means', 'me', 'we', 'want',\n",
       "       'never', 'c', 'news', 'use', 'jobs', 'apple', 'scala', 'html5',\n",
       "       'days', 'android', '40', 'ice', 'has', 'idea', 'fear', 'against',\n",
       "       'tool', 'net', 'issues', 'statistics', 'only', 'http', 'server',\n",
       "       'firefox', 'os', 'health', 'uses', 'googles', 'services', '|',\n",
       "       'youtube', 'art', 'pop', 'says', 'getting', 'move', 'car',\n",
       "       'engine', 'free', 'if', 'have', 'work', 'github', 'dynamic',\n",
       "       'learning', 'history', 'people', 'over', 'language', 'code',\n",
       "       'education', 'india', 'website', 'source', 'year', 'system', '2',\n",
       "       'desktop', 'bitcoin', 'court', 'advice', 'site', 'day', 'writing',\n",
       "       'simple', 'client', 'development', 'cover', 'around', 'ibm', '3d',\n",
       "       'content', 'management', 'small', 'maps', '11', 'do', 'more',\n",
       "       'needs', 'support', 'early', 'css', 'company', 'turns', 'better',\n",
       "       'working', 'real', 'full', 'results', 'haskell', 'tweets',\n",
       "       'between', 'series', 'silicon', 'would', 'gmail', 'black',\n",
       "       'feature', 'social', 'will', 'x', 'kill', 'model', 'end',\n",
       "       'missing', 'successful', 'valley', 'today', 'update', 'creative',\n",
       "       '8', 'did', 'could', 'yahoo', 'engineering', 'like', 'high',\n",
       "       'case', 'big', 'isnt', 'users', 'ads', 'hackers', 'through',\n",
       "       'ever', 'million', 'ios', 'attack', 'used', 'tracking', 'should',\n",
       "       'book', 'cheap', 'personal', 'home', '2010', '3', 'help', 'game',\n",
       "       'nodejs', 'built', 'food', 'office', 'available', 'linux',\n",
       "       'machine', 'digital', 'copyright', 'features', 'list', 'links',\n",
       "       'our', 'was', 'life', 'creating', 'up', 'next', 'does', 'seo',\n",
       "       'music', 'way', 'developers', 'their', 'much', 'dead', 'developer',\n",
       "       '7', 'dropbox', 'based', 'marketing', 'about', 'vs', 'just',\n",
       "       'less', 'where', 'key', 'chrome', 'ceo', 'these', 'since',\n",
       "       'hosting', 'project', 'women', 'than', 'climate', 'change',\n",
       "       'worlds', 'collection', 'down', 'touch', 'hacked', 'generator',\n",
       "       'kids', 'consumer', 'private', 'community', 'wordpress', '10',\n",
       "       'programmers', 'steve', 'billion', 'even', 'public', 'conference',\n",
       "       'sites', 'database', '2011', 'everything', 'lessons', 'learned',\n",
       "       'word', 'review', 'applications', 'lost', 'customer', 'they',\n",
       "       'emacs', 'come', 'account', 'sales', 'money', 'nokia', 'off',\n",
       "       'learn', 'ad', 'php', 'must', 'away', 'face', 'two', 'steps',\n",
       "       'whats', 'nexus', '2013', 'python', 'world', 'wall', 'bad',\n",
       "       'speed', 'light', 'future', 'who', 'no', 'story', 'group', 'wants',\n",
       "       'netflix', 'pay', 'popular', 'price', 'page', 'lets', 'tablets',\n",
       "       'math', 'san', 'challenge', 'article', 'notes', 'resources',\n",
       "       'networks', '20', 'still', 'lean', 'other', 'blackberry', 'report',\n",
       "       'investors', 'tells', 'there', 'investment', 'trust', 'center',\n",
       "       'photos', 'product', 'library', 'feedback', 'bug', 'americans',\n",
       "       'family', 'sdk', 'exchange', 'git', 'last', 'cost', 'program', 'y',\n",
       "       'store', 'beautiful', 'save', 'launches', 'air', 'sports',\n",
       "       'funding', 'look', 'run', 'every', 'cell', 'editor', 'awesome',\n",
       "       'too', 'know', 'return', 'study', 'easy', 'version', 'lawyer',\n",
       "       'watch', 'biggest', 'distribution', 'advertising', 'privacy',\n",
       "       'add', 'dear', 'ai', 'win', 'put', 'experience', 'science',\n",
       "       'fails', 'questions', 'beta', 'go', 'cool', 'travel', 'class',\n",
       "       'virtual', 'ways', 'application', 'skills', 'became', 'death',\n",
       "       'visualization', 'latest', 'tools', 'ruby', 'letter', 'media',\n",
       "       'super', 'coming', 'designers', 'growth', 'started', 'love',\n",
       "       'javascript', 'minutes', 'java', 'rails', 'amazing', 'left',\n",
       "       'movie', 'keep', 'young', 'experiment', 'were', '100', 'download',\n",
       "       'fake', 'ipad', '6', 'ask', 'worth', 'photo', 'share', 'crisis',\n",
       "       'computing', 'trends', 'again', 'hacking', 'interview', 'designer',\n",
       "       'things', 'say', 'view', 'credit', 'card', 'information', 'tips',\n",
       "       'when', 'youre', 'names', 'head', 'california', 'launch', 'before',\n",
       "       'smart', 'difference', 'buy', 'apache', 'algorithm', 'fast',\n",
       "       'fight', 'att', '2012', 'domain', 'wireless', 'hiring', 'made',\n",
       "       'robots', 'old', 'acquires', 'games', 'right', 'flaw', 'samsung',\n",
       "       'galaxy', 'smartphone', 'apples', 'america', 'scientists',\n",
       "       'little', 'interactive', 'introduction', 'alternative', 'plan',\n",
       "       'energy', 'vulnerability', 'wrong', 'complete', 'selling', 'local',\n",
       "       'cant', 'talks', 'zuckerberg', 'cards', 'possible', 'user', 'yc',\n",
       "       'deal', 'team', 'college', 'students', 'interesting', 'pictures',\n",
       "       'coding', 'makes', 'girls', 'inside', 'systems', 'kickstarter',\n",
       "       'thoughts', 'nasa', 'ideas', '18', 'let', 'storage', 'garden',\n",
       "       'hard', 'without', 'body', 'secure', 'brain', 'sell', 'workers',\n",
       "       'house', 'funny', 'city', 'jquery', 'claims', 'research', 'name',\n",
       "       'take', 'care', 'fun', 'contest', '500', 'got', 'long', 'ui',\n",
       "       'powered', 'demo', 'stanford', 'products', 'looking', 'clone',\n",
       "       'verizon', 'another', 'matter', 'revenue', 'healthy', 'wins',\n",
       "       'hunt', 'c#', 'making', 'venture', 'war', 'see', 'led', '14',\n",
       "       'gates', 'warns', 'erlang', 'pirate', 'bay', 'shoes', 'stream',\n",
       "       'economy', 'london', 'hit', 'obama', 'uk', 'preview', 'compiler',\n",
       "       'manager', 'sharing', 'sale', 'competition', 'diet', 'reasons',\n",
       "       'nike'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = []\n",
    "\n",
    "counts.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
