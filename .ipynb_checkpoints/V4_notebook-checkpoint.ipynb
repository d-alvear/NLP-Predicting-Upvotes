{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Predicting Upvotes Based on Headline\n",
    "## Introduction\n",
    "Hacker News is a community where users can submit articles, and other users can upvote those articles. The articles with the most upvotes make it to the front page, where they're more visible to the community.\n",
    "## Goal\n",
    "In this project, I'll be predicting the number of upvotes articles received, based on their headlines. Because upvotes are an indicator of popularity, I'll discover which types of articles tend to be the most popular.\n",
    "## Data\n",
    "\n",
    "The data set consists of submissions users made to Hacker News from 2006 to 2015. Developer Arnaud Drizard used the Hacker News API to scrape the data, which can be found in one of his [GitHub repositories](https://github.com/arnauddri/hn).\n",
    "\n",
    "* `submission_time` - When the article was submitted\n",
    "* `upvotes` - The number of upvotes the article received\n",
    "* `url` - The base URL of the article\n",
    "* `headline` - The article's headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_time</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-05T16:20:01.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>Safe Conferences Are Deliberately Designed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-27T15:23:57Z</td>\n",
       "      <td>1</td>\n",
       "      <td>nikefreerun2shoesuk.com</td>\n",
       "      <td>Nike Free 7.0 V2 Men's Shoes In Black / Gray /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-29T22:52:24Z</td>\n",
       "      <td>3</td>\n",
       "      <td>neillcorlett.com</td>\n",
       "      <td>y Own HTTP Daemon - Simple daemon in Linux x86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-25T07:21:44Z</td>\n",
       "      <td>1</td>\n",
       "      <td>meetlipsticklesbians.com</td>\n",
       "      <td>emory card xbox 360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-09T09:59:34Z</td>\n",
       "      <td>2</td>\n",
       "      <td>arstechnica.com</td>\n",
       "      <td>OWC launching SandForce-based SSDs for latest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            submission_time  upvotes                       url  \\\n",
       "0  2015-01-05T16:20:01.000Z        1                medium.com   \n",
       "1      2012-03-27T15:23:57Z        1   nikefreerun2shoesuk.com   \n",
       "2      2012-10-29T22:52:24Z        3          neillcorlett.com   \n",
       "3      2011-08-25T07:21:44Z        1  meetlipsticklesbians.com   \n",
       "4      2011-01-09T09:59:34Z        2           arstechnica.com   \n",
       "\n",
       "                                            headline  \n",
       "0         Safe Conferences Are Deliberately Designed  \n",
       "1  Nike Free 7.0 V2 Men's Shoes In Black / Gray /...  \n",
       "2  y Own HTTP Daemon - Simple daemon in Linux x86...  \n",
       "3                                emory card xbox 360  \n",
       "4  OWC launching SandForce-based SSDs for latest ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"submissions.csv\")\n",
    "data.columns = [\"submission_time\", \"upvotes\", \"url\", \"headline\"]\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363967, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is pretty large, I'm going to shuffle the rows of the data frame and use a quarter of the data for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "shuffled_index = np.random.permutation(data.index)\n",
    "data = data.reindex(shuffled_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = data.iloc[:6000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "My goal is to train a linear regression algorithm that predicts the number of upvotes a headline would receive. To do this, I'll need to convert each headline to a numerical representation. I will be using the 'bag of words' model, which represents each piece of text as a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['You', \"don't\", 'need', 'millions', 'of', 'dollars'], ['Ricky', 'Yean', 'Of', 'Crowdbooster', 'On', 'Bringing', 'Value', 'As', 'A', 'CEO', 'And', 'Customer', 'Development'], ['Activision', 'shows', 'off', 'next-gen', 'facial', 'rendering'], ['ail', 'security', 'tips'], ['Two', 'Sites', 'to', 'Create', 'Dummy', 'Images']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_headlines = []\n",
    "for item in submissions['headline']:\n",
    "    tokenized_headlines.append(item.split())\n",
    "\n",
    "#preview the data  \n",
    "print(tokenized_headlines[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have my tokens, I know they will need some processing to help with making predictions later on. I will need to get rid of punctuation, and make all words lowercase for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"â€™\", \"?\", \"/\", \n",
    "               \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_headlines:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        tokens.append(token)\n",
    "    clean_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will retrieve all unique words from each headline, create a matrix, and assign those words as column headers. After, I will populate the matrix with the number of token occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = {}\n",
    "for tokens in clean_tokenized:\n",
    "    for token in tokens:\n",
    "        if token in unique_tokens:\n",
    "            unique_tokens[token] += 1\n",
    "        elif token not in unique_tokens:\n",
    "            unique_tokens[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = []\n",
    "for key in unique_tokens.keys():\n",
    "    if len(key) < "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = unique_tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>you</th>\n",
       "      <th>dont</th>\n",
       "      <th>need</th>\n",
       "      <th>millions</th>\n",
       "      <th>of</th>\n",
       "      <th>dollars</th>\n",
       "      <th>ricky</th>\n",
       "      <th>yean</th>\n",
       "      <th>crowdbooster</th>\n",
       "      <th>on</th>\n",
       "      <th>...</th>\n",
       "      <th>overwatch</th>\n",
       "      <th>multiplayer</th>\n",
       "      <th>httpaddthiscombookmarkphpv=250username=xa4d2b47597ad291fb</th>\n",
       "      <th>penguin</th>\n",
       "      <th>nonprofits</th>\n",
       "      <th>bangor</th>\n",
       "      <th>pfg</th>\n",
       "      <th>mf</th>\n",
       "      <th>stain</th>\n",
       "      <th>extax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 11400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   you  dont  need  millions  of  dollars  ricky  yean  crowdbooster  on  ...  \\\n",
       "0    0     0     0         0   0        0      0     0             0   0  ...   \n",
       "1    0     0     0         0   0        0      0     0             0   0  ...   \n",
       "2    0     0     0         0   0        0      0     0             0   0  ...   \n",
       "3    0     0     0         0   0        0      0     0             0   0  ...   \n",
       "4    0     0     0         0   0        0      0     0             0   0  ...   \n",
       "\n",
       "   overwatch  multiplayer  \\\n",
       "0          0            0   \n",
       "1          0            0   \n",
       "2          0            0   \n",
       "3          0            0   \n",
       "4          0            0   \n",
       "\n",
       "   httpaddthiscombookmarkphpv=250username=xa4d2b47597ad291fb  penguin  \\\n",
       "0                                                  0                0   \n",
       "1                                                  0                0   \n",
       "2                                                  0                0   \n",
       "3                                                  0                0   \n",
       "4                                                  0                0   \n",
       "\n",
       "   nonprofits  bangor  pfg  mf  stain  extax  \n",
       "0           0       0    0   0      0      0  \n",
       "1           0       0    0   0      0      0  \n",
       "2           0       0    0   0      0      0  \n",
       "3           0       0    0   0      0      0  \n",
       "4           0       0    0   0      0      0  \n",
       "\n",
       "[5 rows x 11400 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.DataFrame(0, index=np.arange(len(clean_tokenized)), columns=cols)\n",
    "counts.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
